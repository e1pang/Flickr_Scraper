# -*- coding: utf-8 -*-
"""
Created on Fri Jun 29 18:53:58 2018

@author: Eric
"""

import time
import requests
import re
import os
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup

def download(myinput, mydir = "TestDir2"):    
    if isinstance(myinput, str) or isinstance(myinput, bytes):        
        res = requests.get(myinput)
        res.raise_for_status()              
        outfile = mydir + "/" + os.path.basename(myinput)
        playFile = open(outfile, 'wb')
        for chunk in res.iter_content(100000):
            playFile.write(chunk)
        playFile.close()
    elif isinstance(myinput, list):
        print('Start: download')
        for i in myinput:
            download(i, mydir)
        print('End: download')
    else:
        pass
    
#can ONLY take LIST input, shows images being saved
def downloadListShow(list_Input, mydir= 'TestDir2'):
    print('Start: download')
    browser=webdriver.Chrome()
    for link in list_Input:
        browser.get(link)
        res=requests.get(link)
        res.raise_for_status()        
        path=mydir + "/" + os.path.basename(link)
        saveFile=open(path, 'wb')
        for chunk in res.iter_content(100000):
            saveFile.write(chunk)
        saveFile.close()    
    browser.quit()
    print('End: download')

#Interruptions do not work for Keyword searchings, and I do not recommend early stop for album and photostream
class Flickr_Slow(object):
    
    def __init__(self, browser = None):
        #https://stackoverflow.com/questions/7160737/python-how-to-validate-a-url-in-python-malformed-or-not
        self.regex = re.compile(
        r'^(?:http|ftp)s?://' # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|' #domain...
        r'localhost|' #localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})' # ...or ip
        r'(?::\d+)?' # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        
        if browser==None:
            self.browser=webdriver.Chrome()
        else:
            self.browser=browser       
        
        
            
    def isURL(self, to_check):
        return re.match(self.regex,to_check)
    
    #can accept keywords to search or urls to an ALBUM or a user's PHOTOSTREAM
    #the largest image will be taken, guaranteed to be available
    #calls the functions: scrollKeyWord, links_to_list
    #limits are approximate
    def run(self, keyword_or_url, max_images=100, search_time_secs=30):
        images= []
        #call the right search function
        if self.isURL(keyword_or_url):
            #print('search url')
            link = keyword_or_url
            images = self.searchAlbumPhotostream(link, max_images, search_time_secs)
        else:
            #print('keyword')
            link = "https://www.flickr.com/search/?text="+str(keyword_or_url)            
            images = self.searchKeyWord(link, search_time_secs)
            
        print('images found: ', len(images))
        return images
    
      #calls the functions: scrollKeyWord, links_to_list
    def searchKeyWord(self, link, search_time_secs):
        images=[]
        self.browser.get(link)
        try:
            self.scrollKeyWord(search_time_secs) #scroll to get whole page   
           
        except:
            images=self.links_to_list(search_type='keyword')        
            return images
        images=self.links_to_list(search_type='keyword') 
        return images
            
      
     
    #purpose of function is to scroll and load the page 
    #calls the functions: scrollKeyWord, links_to_list
    def scrollKeyWord(self, time_scroll_secs, persistence=20):
        print('Start: scrollKeyWord')
        try:
            start=time.time()       
            action=self.browser.find_element_by_tag_name('a')
            count=0
            while count<persistence and time.time()-start< time_scroll_secs:    
                for i in range(40): 
                    action.send_keys(Keys.PAGE_DOWN)
                try:
                    e=self.browser.find_element_by_class_name('alt')
                    e.click()
                except:                
                    count=count+1                
                    continue
            print('End: scrollKeyWord')
            #print('persisted: ',count, ', elapsed: ', time.time()-start)
        except:
            print('Interrupted: scrollKeyWord')
            
     #calls the functions: links_to_list    
    def searchAlbumPhotostream(self, link, max_images, search_time_secs):
        print('Start: searchAlbumPhotostream')
        start=time.time()
        images=[]
        
        self.browser.get(link)        
        soup=BeautifulSoup(self.browser.page_source,'html.parser')    
        #determine if photostream or album
        page_type = soup.find('html')['class'][2] 
        if page_type == 'html-photostream-page-view':
            search_type='photostream'
            #print('photostream')
        elif page_type == 'html-album-page-view':
            search_type='album'
            #print('album')
        else:            
            print (link, ' is not a valid url to an ALBUM or a PHOTOSTREAM')           
            return []  
        
        while True:
            try:
                self.browser.get(link)   
                action=self.browser.find_element_by_tag_name('a')
                for i in range(40): 
                    action.send_keys(Keys.PAGE_DOWN)
                    #print(i, ' ',self.browser.execute_script("return document.body.scrollHeight"))     #to monitor height   
                time.sleep(2)
                #soup=BeautifulSoup(self.browser.page_source,'html.parser') 
                
                images.extend(self.links_to_list(search_type))
                
                if time.time()-start<search_time_secs and len(images)<max_images:
                    soup=BeautifulSoup(self.browser.page_source,'html.parser')
                    next_page=soup.find('a',rel='next')
                    if next_page:
                        link=next_page.get('href')
                        link="".join(['https://www.flickr.com',link])    
                        print('Starting Next Page')
                    else:
                        break
                else:
                    break
            except: #when the user interupts
                print('Interrupted: searchAlbumPhotostream')                     
                return images
        #print('Time elapsed: ', time.time()-start) 
        print('End: searchAlbumPhotostream') 
        return images
    
    #gets links in the open self.browser page into a list
    def links_to_list(self, search_type):
        print('Start: links_to_list')
        img_list_temp=[]
        img_list_complete=[]
        
        try: 
            search_elements=self.browser.find_elements_by_class_name('overlay')          
            
            for element in search_elements:    
                img_list_temp.append(element.get_attribute('href'))                 
            
            for link in img_list_temp:                
                if search_type=='album': #fix link
                    link=link[:link.find('/in/album-')]
                elif search_type=='keyword':
                    link=link[:link.find('/in/photolist-')]        
        
                html_page=requests.get(link+'/sizes/o/')
                html=html_page.text
                soup= BeautifulSoup(html,'html.parser')
                
                soup1=soup.find(id='allsizes-photo')
                soup2=soup1.find('img')
                img_list_complete.append(soup2['src'])
            print('End: links_to_list')
            return img_list_complete    
        except:
            print('Interrupted: links_to_list')
            return img_list_complete
    
    
    
    def viewImages(self, image_list, time_sleep=.5):
        #print("Start View Images")        
        for link in image_list:
            self.browser.get(link)
            time.sleep(time_sleep)        
        #print("End View Images")
        
    def close(self):
        self.browser.close()
        #print("Closed Browser")  
        
if __name__ == '__main__':
    start=time.time()
    images=[]
    fs=Flickr_Slow()    
    
    user_input= 'keyword to search or a url to an album/photostream'   
    images=fs.run(user_input, max_images=101, search_time_secs=50)  
    
    download(images)       
    print(len(images))    
    print(time.time()-start)    
    #fs.close()




    
    
    
    
    
