# -*- coding: utf-8 -*-
"""
Created on Thu Jun 28 21:03:19 2018

@author: Eric
"""

import time
import requests
import re
import os
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup

#download taken from: https://github.com/xjdeng/pinterest-image-scraper/blob/master/pinterest_scraper/scraper.py
def download(myinput, mydir = "TestDir"):    
    if isinstance(myinput, str) or isinstance(myinput, bytes):        
        res = requests.get(myinput)
        res.raise_for_status()              
        outfile = mydir + "/" + os.path.basename(myinput)
        playFile = open(outfile, 'wb')
        for chunk in res.iter_content(100000):
            playFile.write(chunk)
        playFile.close()
    elif isinstance(myinput, list):
        print('Start: download')
        for i in myinput:
            download(i, mydir)
        print('End: download')
    else:
        pass
    
#can ONLY take LIST input, shows images being saved
def downloadListShow(list_Input, mydir= 'TestDir'):
    print('Start: download')
    browser=webdriver.Chrome()
    for link in list_Input:
        browser.get(link)
        res=requests.get(link)
        res.raise_for_status()        
        path=mydir + "/" + os.path.basename(link)
        saveFile=open(path, 'wb')
        for chunk in res.iter_content(100000):
            saveFile.write(chunk)
        saveFile.close()    
    browser.quit()
    print('End: download')


#each function can be early-stopped with 'cntrl-c' and what it has collected so far will be returned
class Flickr_Fast(object):
    
    def __init__(self, browser = None):
        #https://stackoverflow.com/questions/7160737/python-how-to-validate-a-url-in-python-malformed-or-not
        self.regex = re.compile(
        r'^(?:http|ftp)s?://' # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|' #domain...
        r'localhost|' #localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})' # ...or ip
        r'(?::\d+)?' # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        
        if browser==None:
            self.browser=webdriver.Chrome()
        else:
            self.browser=browser       
            
    def isURL(self, to_check):
        return re.match(self.regex,to_check)

            
    #can accept keywords to search or urls to an ALBUM or a user's PHOTOSTREAM

    #keyword search can only be limited by search time, album and photostream by both
    #limits are approximate
    
    #Size Codes: not all sizes exist, default is Large 1024
    #s-Square 75 (75 x 75)
    #q-Square 150 (150 x 150)
    #t-Thumbnail (100 x 71)
    #m-Small 240 (240 x 171)
    #n-Small 320 (320 x 229)
    #z-Medium 640 (640 x 458)
    #c-Medium 800 (800 x 572)
    #b-Large 1024 (1024 x 732) <---- I found this one most useful
    #h-Large 1600 (1600 x 1143)
    #k-Large 2048 (2048 x 1463)
    
    #calls the functions: isURL, searchAlbumPhotostream, searchKeyWord
    def run(self, keyword_or_url, image_size= 'b', max_images=500, search_time_secs=500):
        images= []
        #call the right search function
        if self.isURL(keyword_or_url):
            #print('search url')
            link = keyword_or_url
            images = self.searchAlbumPhotostream(link, image_size, max_images, search_time_secs)
        else:
            #print('keyword')
            link = "https://www.flickr.com/search/?text="+str(keyword_or_url)            
            images = self.searchKeyWord(link, image_size, search_time_secs)
            
        print('Images Found: ', len(images))
        return images
        
    #calls the functions: scrollKeyWord, links_to_list
    def searchKeyWord(self, link, image_size, search_time_secs):
        images=[]
        self.browser.get(link)
        try:
            self.scrollKeyWord(search_time_secs) #scroll to get whole page                        
#            class_search = 'view photo-list-photo-view requiredToShowOnServer awake' 
#            class_search2 = 'view photo-list-photo-view awake'         
#            images=self.links_to_list(soup, [class_search, class_search2], image_size)#        
#            return images
            soup=BeautifulSoup(self.browser.page_source,'html.parser')  
        except:            
            soup=BeautifulSoup(self.browser.page_source,'html.parser')              
            class_search = 'view photo-list-photo-view requiredToShowOnServer awake' 
            class_search2 = 'view photo-list-photo-view awake'         
            images=self.links_to_list(soup, [class_search, class_search2], image_size)        
            return images
        
        #soup=BeautifulSoup(self.browser.page_source,'html.parser')  
        class_search = 'view photo-list-photo-view requiredToShowOnServer awake' 
        class_search2 = 'view photo-list-photo-view awake'         
        images=self.links_to_list(soup, [class_search, class_search2], image_size)        
        return images
     
    #purpose of function is to scroll and load the page 
    #calls the functions: scrollKeyWord, links_to_list
    def scrollKeyWord(self, time_scroll_secs, persistence=20):
        print('Start: scrollKeyWord')
        try:
            start=time.time()       
            action=self.browser.find_element_by_tag_name('a')
            count=0
            while count<persistence and time.time()-start< time_scroll_secs:                
                for i in range(40): 
                    action.send_keys(Keys.PAGE_DOWN)
                try:
                    e=self.browser.find_element_by_class_name('alt')
                    e.click()
                except:                
                    count=count+1                
                    continue
            print('End: scrollKeyWord')
        except:
            print('Interrupted: scrollKeyWord')
        
    #calls the functions: links_to_list    
    def searchAlbumPhotostream(self, link, image_size, max_images, search_time_secs): 
        print('Start: searchAlbumPhotostream')
        start=time.time()
        images=[]
        
        self.browser.get(link)        
        soup=BeautifulSoup(self.browser.page_source,'html.parser')    
        #determine if photostream or album
        page_type = soup.find('html')['class'][2] 
        if page_type == 'html-photostream-page-view':
            class_search = 'view photo-list-photo-view requiredToShowOnServer photostream awake' 
            class_search2 = 'view photo-list-photo-view photostream awake'
            #print('photostream')
        elif page_type == 'html-album-page-view':
            class_search = 'view photo-list-photo-view requiredToShowOnServer awake'          
            class_search2 = 'view photo-list-photo-view awake'
            #print('album')
        else:            
            print (link, ' is not a valid url to an ALBUM or a PHOTOSTREAM')           
            return []  
        
        while True:
            try:
                self.browser.get(link)   
                action=self.browser.find_element_by_tag_name('a')
                for i in range(40): 
                    action.send_keys(Keys.PAGE_DOWN)
                    #print(i, ' ',self.browser.execute_script("return document.body.scrollHeight"))     #to monitor height   
                time.sleep(2)
                soup=BeautifulSoup(self.browser.page_source,'html.parser') 
                
                images.extend(self.links_to_list(soup, [class_search, class_search2], image_size))
                
                if time.time()-start<search_time_secs and len(images)<max_images:
                    next_page=soup.find('a',rel='next')
                    if next_page:
                        link=next_page.get('href')
                        link="".join(['https://www.flickr.com',link])    
                        print('Starting Next Page')
                    else:
                        break
                else:
                    break
            except:
                print('Interrupted: searchAlbumPhotostream')                
                return images
        print('End: searchAlbumPhotostream')       
        return images
    
    #gets links in a page into a list
    def links_to_list(self, soup, class_search, image_size):
        print('Start: links_to_list')
        images=[]        
        try:
            for x in soup.find_all(attrs={"class":class_search}):
                style= x.get('style')  
                #find url, classify and modify, and finally add to list of image urls
                restOfLink=style[style.find('c1.staticflickr.com'):style.find('.jpg')]
                if restOfLink[-2]=="_":      
                    images.append(''.join(['https://',restOfLink[:-2],'_', image_size, '.jpg']))
                else:
                    images.append(''.join(['https://',restOfLink,'_', image_size, '.jpg']))
            print('End: links_to_list')
            return images   
        
        except:
            print('Interrupted: links_to_list')
            return images
    
    def viewImages(self, image_list, time_sleep=.5):
        print("Start View Images")        
        for link in image_list:
            self.browser.get(link)
            time.sleep(time_sleep)        
        print("End View Images")
        
    def close(self):
        self.browser.close()
        print("Close Browser")        
        
if __name__ == '__main__':
     
    start=time.time()
    images=[]
    ff=Flickr_Fast()    
    user_input= 'keyword to search or a url to an album/photostream'
    images=ff.run(user_input, max_images=101, search_time_secs=50)  
    #download(images)   
    print(len(images))    
    print(time.time()-start)    
    #ff.close()
